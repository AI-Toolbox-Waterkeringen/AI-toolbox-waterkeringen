{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n",
      "[Open3D INFO] Resetting default logger to print to terminal.\n",
      "Using pdal version 3.4.5\n"
     ]
    }
   ],
   "source": [
    "import pdal\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import matplotlib.image\n",
    "import pathlib\n",
    "import subprocess\n",
    "import json\n",
    "import tqdm.auto as tqdm\n",
    "import shapely.geometry\n",
    "from pycocotools.coco import COCO\n",
    "import open3d\n",
    "from open3d.web_visualizer import draw\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import cv2\n",
    "import zlib\n",
    "import base64\n",
    "import io\n",
    "from PIL import Image\n",
    "\n",
    "print(f\"Using pdal version {pdal.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_las_bounds(lasfolder):\n",
    "    \"\"\" \"\"\"\n",
    "    lasfiles = [p for p in pathlib.Path(lasfolder).iterdir() if p.suffix == \".laz\"]\n",
    "    df_las = []\n",
    "    for p in tqdm.tqdm(lasfiles):\n",
    "        # decode stdout from bytestring and convert to a dictionary\n",
    "        result = subprocess.run(\n",
    "            [\"pdal\", \"info\", str(p)], stderr=subprocess.PIPE, stdout=subprocess.PIPE\n",
    "        )\n",
    "        json_result = json.loads(result.stdout.decode())\n",
    "        maxx, maxy, maxz, minx, miny, minz = json_result[\"stats\"][\"bbox\"][\"native\"][\n",
    "            \"bbox\"\n",
    "        ].values()\n",
    "        geom = shapely.geometry.box(minx, miny, maxx, maxy)\n",
    "        df_las.append((p.stem, str(p), maxx, maxy, maxz, minx, miny, minz, geom))\n",
    "    df_las = pd.DataFrame(\n",
    "        df_las,\n",
    "        columns=[\n",
    "            \"name\",\n",
    "            \"path\",\n",
    "            \"maxx\",\n",
    "            \"maxy\",\n",
    "            \"maxz\",\n",
    "            \"minx\",\n",
    "            \"miny\",\n",
    "            \"minz\",\n",
    "            \"geometry\",\n",
    "        ],\n",
    "    )\n",
    "    df_las = gpd.GeoDataFrame(df_las, geometry=\"geometry\", crs=\"epsg:28992\")\n",
    "    return df_las\n",
    "\n",
    "\n",
    "def find_tile_bounds(root_tilepath, concat=True):\n",
    "    cell_files = []\n",
    "    for p in pathlib.Path(root_tilepath).iterdir():\n",
    "        if p.is_dir():\n",
    "            cell_files += find_tile_bounds(p, concat=False)\n",
    "        elif p.is_file() and p.suffix == \".gpkg\" and \"cells_intersect\" in p.stem:\n",
    "            df = gpd.read_file(p)\n",
    "            df[\"name\"] = p.stem.replace(\"_cells_intersects\", \"\")\n",
    "            cell_files.append(df.copy())\n",
    "    if concat:\n",
    "        cell_files = pd.concat(cell_files)\n",
    "    return cell_files\n",
    "\n",
    "\n",
    "def get_lasdata(las_file, xmin, xmax, ymin, ymax):\n",
    "    jsondata = f\"\"\"\n",
    "    [\n",
    "        \"{lasfile.path}\",\n",
    "        {{\n",
    "            \"type\":\"filters.expression\",\n",
    "            \"expression\":\"(X >= {xmin} && X <= {xmax} && Y >= {ymin} && Y <= {ymax})\"\n",
    "        }}\n",
    "    ]\n",
    "    \"\"\"\n",
    "    pipeline = pdal.Pipeline(jsondata)\n",
    "    _ = pipeline.execute()\n",
    "    arrays = pipeline.arrays\n",
    "    assert len(arrays) == 1\n",
    "    #         metadata = pipeline.metadata\n",
    "    #         log = pipeline.log\n",
    "    arrays = pd.DataFrame(arrays[0])\n",
    "    return arrays\n",
    "\n",
    "\n",
    "def get_lasground(las_file, xmin, xmax, ymin, ymax):\n",
    "    jsondata = f\"\"\"\n",
    "    [\n",
    "        \"{lasfile.path}\",\n",
    "        {{\n",
    "            \"type\":\"filters.expression\",\n",
    "            \"expression\":\"(X >= {xmin} && X <= {xmax} && Y >= {ymin} && Y <= {ymax})\"\n",
    "        }},\n",
    "        {{\n",
    "            \"type\":\"filters.assign\",\n",
    "            \"assignment\":\"Classification[:]=0\"\n",
    "        }},\n",
    "        {{\n",
    "            \"type\":\"filters.smrf\",\n",
    "            \"scalar\": 1.2,\n",
    "            \"slope\": 0.2,\n",
    "            \"threshold\": 0.45,\n",
    "            \"window\": 16.0\n",
    "        }}\n",
    "    ]\n",
    "    \"\"\"\n",
    "    pipeline = pdal.Pipeline(jsondata)\n",
    "    _ = pipeline.execute()\n",
    "    arrays = pipeline.arrays\n",
    "    assert len(arrays) == 1\n",
    "    #         metadata = pipeline.metadata\n",
    "    #         log = pipeline.log\n",
    "    arrays = pd.DataFrame(arrays[0])\n",
    "    return arrays\n",
    "\n",
    "\n",
    "def base64_2_mask(s):\n",
    "    z = zlib.decompress(base64.b64decode(s))\n",
    "    n = np.frombuffer(z, np.uint8)\n",
    "    mask = cv2.imdecode(n, cv2.IMREAD_UNCHANGED)[:, :, 3].astype(bool)\n",
    "    return mask\n",
    "\n",
    "\n",
    "def mask_2_base64(mask):\n",
    "    img_pil = Image.fromarray(np.array(mask, dtype=np.uint8))\n",
    "    img_pil.putpalette([0, 0, 0, 255, 255, 255])\n",
    "    bytes_io = io.BytesIO()\n",
    "    img_pil.save(bytes_io, format=\"PNG\", transparency=0, optimize=0)\n",
    "    bytes = bytes_io.getvalue()\n",
    "    return base64.b64encode(zlib.compress(bytes)).decode(\"utf-8\")\n",
    "\n",
    "\n",
    "def get_overlap_laz(gdf_laz, gdf_tiles):\n",
    "    \"\"\" \"\"\"\n",
    "    # Create a spatial index for gdf2 to efficiently query overlaps\n",
    "    sindex_gdf_tiles = gdf_tiles.sindex\n",
    "    # Use a list comprehension with any() to find overlaps using the spatial index\n",
    "    overlaps_mask = [\n",
    "        any(\n",
    "            gdf_tiles.iloc[\n",
    "                sindex_gdf_tiles.query(geometry, predicate=\"intersects\")\n",
    "            ].geometry.intersects(geometry)\n",
    "        )\n",
    "        for geometry in gdf_laz.geometry\n",
    "    ]\n",
    "    # Apply the mask to gdf1 to filter rows that overlap with gdf2\n",
    "    overlapping_gdf = gdf_laz[overlaps_mask]\n",
    "    return overlapping_gdf\n",
    "\n",
    "\n",
    "def zip_lasfiles(gdf_las):\n",
    "    # List of file paths you want to include in the zip file\n",
    "    files_to_zip = list(gdf_las.path)\n",
    "    zip_file_name = \"lasfiles.zip\"\n",
    "    # Create a zip file\n",
    "    with zipfile.ZipFile(zip_file_name, \"w\", zipfile.ZIP_DEFLATED) as zipf:\n",
    "        for file in files_to_zip:\n",
    "            # Add each file to the zip file\n",
    "            zipf.write(file, arcname=file.split(\"/\")[-1])\n",
    "    print(f\"Created zip file {zip_file_name} containing {len(files_to_zip)} files.\")\n",
    "\n",
    "\n",
    "def show_anns(anns):\n",
    "    if len(anns) == 0:\n",
    "        return\n",
    "    sorted_anns = sorted(anns, key=(lambda x: x[\"area\"]), reverse=True)\n",
    "    ax = plt.gca()\n",
    "    ax.set_autoscale_on(False)\n",
    "\n",
    "    img = np.ones(\n",
    "        (\n",
    "            sorted_anns[0][\"segmentation\"].shape[0],\n",
    "            sorted_anns[0][\"segmentation\"].shape[1],\n",
    "            4,\n",
    "        )\n",
    "    )\n",
    "    img[:, :, 3] = 0\n",
    "    for ann in sorted_anns:\n",
    "        m = ann[\"segmentation\"]\n",
    "        color_mask = np.concatenate([np.random.random(3), [0.35]])\n",
    "        img[m] = color_mask\n",
    "    ax.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: '..\\data\\las_bounds_selected.gpkg' already exists!\n",
      "Found 0 las files\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No objects to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFound \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(gdf_las)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m las files\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# geodataframe with geometries of tiles\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m gdf_tilebounds = \u001b[43mfind_tile_bounds\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_tifftiles\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m gdf_tilebounds_selected = gdf_tilebounds.sjoin(gdf_las, how=\u001b[33m\"\u001b[39m\u001b[33minner\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m debug:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 44\u001b[39m, in \u001b[36mfind_tile_bounds\u001b[39m\u001b[34m(root_tilepath, concat)\u001b[39m\n\u001b[32m     42\u001b[39m         cell_files.append(df.copy())\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m concat:\n\u001b[32m---> \u001b[39m\u001b[32m44\u001b[39m     cell_files = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcell_files\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     45\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m cell_files\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\projects\\AI-toolbox-waterkeringen\\scripts\\opschot-detectie\\.pixi\\envs\\default\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:382\u001b[39m, in \u001b[36mconcat\u001b[39m\u001b[34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[39m\n\u001b[32m    379\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m copy \u001b[38;5;129;01mand\u001b[39;00m using_copy_on_write():\n\u001b[32m    380\u001b[39m     copy = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m382\u001b[39m op = \u001b[43m_Concatenator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    383\u001b[39m \u001b[43m    \u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    384\u001b[39m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    385\u001b[39m \u001b[43m    \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    386\u001b[39m \u001b[43m    \u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m=\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    387\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    388\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlevels\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    389\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnames\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    390\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverify_integrity\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverify_integrity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    391\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    392\u001b[39m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[43m=\u001b[49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    393\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    395\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m op.get_result()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\projects\\AI-toolbox-waterkeringen\\scripts\\opschot-detectie\\.pixi\\envs\\default\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:445\u001b[39m, in \u001b[36m_Concatenator.__init__\u001b[39m\u001b[34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[39m\n\u001b[32m    442\u001b[39m \u001b[38;5;28mself\u001b[39m.verify_integrity = verify_integrity\n\u001b[32m    443\u001b[39m \u001b[38;5;28mself\u001b[39m.copy = copy\n\u001b[32m--> \u001b[39m\u001b[32m445\u001b[39m objs, keys = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_clean_keys_and_objs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    447\u001b[39m \u001b[38;5;66;03m# figure out what our result ndim is going to be\u001b[39;00m\n\u001b[32m    448\u001b[39m ndims = \u001b[38;5;28mself\u001b[39m._get_ndims(objs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\projects\\AI-toolbox-waterkeringen\\scripts\\opschot-detectie\\.pixi\\envs\\default\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:507\u001b[39m, in \u001b[36m_Concatenator._clean_keys_and_objs\u001b[39m\u001b[34m(self, objs, keys)\u001b[39m\n\u001b[32m    504\u001b[39m     objs_list = \u001b[38;5;28mlist\u001b[39m(objs)\n\u001b[32m    506\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(objs_list) == \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m507\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mNo objects to concatenate\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    509\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m keys \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    510\u001b[39m     objs_list = \u001b[38;5;28mlist\u001b[39m(com.not_none(*objs_list))\n",
      "\u001b[31mValueError\u001b[39m: No objects to concatenate"
     ]
    }
   ],
   "source": [
    "# config\n",
    "path_lasdata = pathlib.Path(\"../data\")\n",
    "path_lasbounds = pathlib.Path(\"../data/las_bounds_selected.gpkg\")\n",
    "path_tifftiles = pathlib.Path(\"../data/tile_dataset\")\n",
    "debug = True\n",
    "# path with geometry of las files (bounding box)\n",
    "if not path_lasbounds.exists():\n",
    "    gdf_las = make_las_bounds(path_lasdata)\n",
    "    gdf_las.to_file(path_lasbounds)\n",
    "else:\n",
    "    print(f\"File: '{path_lasbounds}' already exists!\")\n",
    "\n",
    "# geodataframe with geometries of las files\n",
    "gdf_las = gpd.read_file(path_lasbounds)\n",
    "print(f\"Found {len(gdf_las)} las files\")\n",
    "\n",
    "# geodataframe with geometries of tiles\n",
    "gdf_tilebounds = find_tile_bounds(path_tifftiles)\n",
    "gdf_tilebounds_selected = gdf_tilebounds.sjoin(gdf_las, how=\"inner\")\n",
    "\n",
    "if debug:\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(12, 5))\n",
    "    gdf_las.plot(ax=ax, edgecolor=\"black\", facecolor=\"None\", linewidth=1)\n",
    "    gdf_tilebounds_selected.plot(ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "overlapping_gdf = get_overlap_laz(gdf_las, gdf_tilebounds_selected.iloc[idx : idx + 1])\n",
    "overlapping_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(16, 12))\n",
    "gdf_las.plot(ax=ax, facecolor=\"white\", edgecolor=\"black\")\n",
    "overlapping_gdf.plot(ax=ax, facecolor=\"white\", edgecolor=\"red\")\n",
    "gdf_tilebounds_selected.plot(ax=ax, facecolor=\"white\", edgecolor=\"blue\")\n",
    "gdf_tilebounds_selected.iloc[idx : idx + 1].plot(\n",
    "    ax=ax, facecolor=\"white\", edgecolor=\"green\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### aanpak ######\n",
    "\n",
    "# 1. per tile, haal laz data op en sla op als copc laz, voeg bestandsnaam toe aan tekstbestand\n",
    "# 2. maak een vpc file van alle bestanden die in het tekstbestand staan\n",
    "\n",
    "\n",
    "def tile_to_copc(gdf_laz, xmin, xmax, ymin, ymax):\n",
    "    \"\"\"\n",
    "    Gets LiDAR point cloud data from file, selects data within tile and exports as Cloud Optimized Point Cloud format\n",
    "    \"\"\"\n",
    "    abs_fp_out = \"test.copc\"\n",
    "    jsondata = f\"\"\"\n",
    "    [\n",
    "        {gdf_laz.iloc[0].path},\n",
    "        {\"type\":\"filters.expression\"},\n",
    "        {\"expression\":\"(X >= {xmin} && X <= {xmax} && Y >= {ymin} && Y <= {ymax})\"}, \n",
    "        {\"type\": \"writers.copc\", filename': {abs_fp_out}}\n",
    "        \n",
    "    ]\"\"\"\n",
    "    print(jsondata)\n",
    "    pipeline = pdal.Pipeline(jsondata)\n",
    "    _ = pipeline.execute()\n",
    "    return\n",
    "\n",
    "\n",
    "tile_to_copc(\n",
    "    overlapping_gdf,\n",
    "    gdf_tilebounds_selected.iloc[idx][\"xmin\"],\n",
    "    gdf_tilebounds_selected.iloc[idx][\"xmax\"],\n",
    "    gdf_tilebounds_selected.iloc[idx][\"ymin\"],\n",
    "    gdf_tilebounds_selected.iloc[idx][\"ymax\"],\n",
    ")\n",
    "\n",
    "# get_lasdata(las_file, xmin, xmax, ymin, ymax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 47\n",
    "overlapping_gdf = get_overlap_laz(gdf_las, gdf_tilebounds_selected.iloc[idx : idx + 1])\n",
    "fig, ax = plt.subplots(1, 1, figsize=(25, 20))\n",
    "gdf_las.plot(ax=ax, facecolor=\"white\", edgecolor=\"black\")\n",
    "overlapping_gdf.plot(ax=ax, facecolor=\"white\", edgecolor=\"red\")\n",
    "gdf_tilebounds_selected.plot(ax=ax, facecolor=\"white\", edgecolor=\"blue\")\n",
    "gdf_tilebounds_selected.iloc[idx : idx + 1].plot(\n",
    "    ax=ax, facecolor=\"white\", edgecolor=\"green\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDir = pathlib.Path(\n",
    "    \"276114_20230714 MUG Hoorn Enkhuizen orthomosaic deel 1/2023-12-11 10_00_58.048\"\n",
    ")\n",
    "dataDir = pathlib.Path(\n",
    "    \"data/supervisely/277426_20230714 MUG Hoorn Enkhuizen orthomosaic deel 6/2023-12-11 12_52_14.810\"\n",
    ")\n",
    "annFile = dataDir.joinpath(\"annotations/instances.json\")\n",
    "imgDir = dataDir.joinpath(\"images\")\n",
    "\n",
    "# initialize COCO api for instance annotations\n",
    "coco = COCO(annFile)\n",
    "print(\"\")\n",
    "\n",
    "cats = coco.loadCats(coco.getCatIds())\n",
    "nms = [cat[\"name\"] for cat in cats]\n",
    "print(\"COCO categories: \\n{}\\n\".format(\" \".join(nms)))\n",
    "\n",
    "# nms = set([cat[\"supercategory\"] for cat in cats])\n",
    "# print(\"COCO supercategories: \\n{}\".format(\" \".join(nms)))\n",
    "\n",
    "catIds = coco.getCatIds(catNms=[\"twijfel opschot\", \"opschot\"])\n",
    "# imgIds = coco.getImgIds(catIds=catIds)\n",
    "imgIds = coco.getImgIds()\n",
    "\n",
    "plt.close(\"all\")\n",
    "for i, imgId in enumerate(imgIds):\n",
    "    # Find tile bounds (X, Y) based on name\n",
    "    imgName = \".\".join(coco.imgs[imgId][\"file_name\"].split(\".\")[:-1])\n",
    "    tile1a = imgName.split(\"_\")[0]\n",
    "    tile1b = int(imgName.split(\"_\")[-1])\n",
    "    cellfile = gdf_tilebounds[\n",
    "        (gdf_tilebounds.index == tile1b) & (gdf_tilebounds.name == tile1a)\n",
    "    ].copy()\n",
    "    assert len(cellfile) == 1\n",
    "    cellfile = cellfile.iloc[0, :].copy()\n",
    "    print(f\"  - {i + 1:>02d}/{len(imgIds):>02d} rgb tile: '{tile1a}' ('{tile1b}')\")\n",
    "\n",
    "    # COCO format img en annotation\n",
    "    img = coco.loadImgs(imgId)[0]\n",
    "\n",
    "    # Laad image in\n",
    "    imgPath = imgDir.joinpath(img[\"file_name\"])\n",
    "    imgRGB = skimage.io.imread(imgPath)\n",
    "    imgGray = skimage.io.imread(imgPath, as_gray=True)\n",
    "\n",
    "    # Laad annotation in\n",
    "    annIds = coco.getAnnIds(imgIds=img[\"id\"], catIds=catIds, iscrowd=None)\n",
    "    anns = coco.loadAnns(annIds)\n",
    "\n",
    "    # Read LIDAR data within the bounds of the image\n",
    "    matching_lasfiles = gdf_las[gdf_las.intersects(cellfile.geometry)].copy()\n",
    "    lidardata1 = []\n",
    "    lidardata2 = []\n",
    "    for lasfile in matching_lasfiles.itertuples():\n",
    "        print(f\"    - las file: {lasfile.path}\")\n",
    "        array1 = get_lasdata(\n",
    "            lasfile.path, cellfile.xmin, cellfile.xmax, cellfile.ymin, cellfile.ymax\n",
    "        )\n",
    "        array1[\"lasfile\"] = pathlib.Path(lasfile.path).stem\n",
    "        array2 = get_lasground(\n",
    "            lasfile.path, cellfile.xmin, cellfile.xmax, cellfile.ymin, cellfile.ymax\n",
    "        )\n",
    "        array2[\"lasfile\"] = pathlib.Path(lasfile.path).stem\n",
    "        lidardata1.append(array1)\n",
    "        lidardata2.append(array2)\n",
    "    lidardata1 = pd.concat(lidardata1, ignore_index=True)\n",
    "    lidardata2 = pd.concat(lidardata2, ignore_index=True)\n",
    "    xstep = (cellfile.xmax - cellfile.xmin) / imgRGB.shape[1]\n",
    "    ystep = (cellfile.ymax - cellfile.ymin) / imgRGB.shape[0]\n",
    "    lidardata1[\"m\"] = ((cellfile.ymax - lidardata1.Y) / ystep).astype(int)\n",
    "    lidardata1[\"n\"] = ((lidardata1.X - cellfile.xmin) / xstep).astype(int)\n",
    "    lidardata2[\"m\"] = ((cellfile.ymax - lidardata2.Y) / ystep).astype(int)\n",
    "    lidardata2[\"n\"] = ((lidardata2.X - cellfile.xmin) / xstep).astype(int)\n",
    "\n",
    "    pcd = open3d.geometry.PointCloud()\n",
    "    pcd.points = open3d.utility.Vector3dVector(lidardata1[[\"X\", \"Y\", \"Z\"]].to_numpy())\n",
    "    plane_model, inliers = pcd.segment_plane(\n",
    "        distance_threshold=0.01, ransac_n=3, num_iterations=1000\n",
    "    )\n",
    "    inlier_cloud = pcd.select_by_index(inliers)\n",
    "    outlier_cloud = pcd.select_by_index(inliers, invert=True)\n",
    "\n",
    "    lidardata3 = pd.DataFrame(np.asarray(outlier_cloud.points), columns=[\"X\", \"Y\", \"Z\"])\n",
    "    lidardata3[\"m\"] = ((cellfile.ymax - lidardata3.Y) / ystep).astype(int)\n",
    "    lidardata3[\"n\"] = ((lidardata3.X - cellfile.xmin) / xstep).astype(int)\n",
    "\n",
    "    # Make plot\n",
    "    fig, axs = plt.subplots(figsize=(15, 5), ncols=3)\n",
    "    plt.sca(axs[0])\n",
    "    plt.imshow(imgGray, cmap=\"gray\")\n",
    "    coco.showAnns(anns, draw_bbox=True)\n",
    "\n",
    "    lp1 = gpd.GeoDataFrame(\n",
    "        lidardata1, geometry=gpd.GeoSeries.from_xy(lidardata1.n, lidardata1.m)\n",
    "    )\n",
    "    lp2 = gpd.GeoDataFrame(\n",
    "        lidardata2, geometry=gpd.GeoSeries.from_xy(lidardata2.n, lidardata2.m)\n",
    "    )\n",
    "    lp3 = gpd.GeoDataFrame(\n",
    "        lidardata3, geometry=gpd.GeoSeries.from_xy(lidardata3.n, lidardata3.m)\n",
    "    )\n",
    "    #     lp1.plot(ax=axs[1], column=\"Z\")\n",
    "    lp1[(lp1.NumberOfReturns > 1) & (lp1.ReturnNumber == 1)].plot(ax=axs[1], column=\"Z\")\n",
    "    #     lp2[lp2.Classification != 2].plot(ax=axs[2], column=\"Z\")\n",
    "    lp3.plot(ax=axs[2], column=\"Z\")\n",
    "\n",
    "    for ax in axs[1:]:\n",
    "        ax.invert_yaxis()\n",
    "        ax.set_xlim(axs[0].get_xlim())\n",
    "        ax.set_ylim(axs[0].get_ylim())\n",
    "    for ax in axs:\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "    if i >= 9:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read LIDAR data within the bounds of the image\n",
    "matching_lasfiles = gdf_las[gdf_las.intersects(cellfile.geometry)].copy()\n",
    "lidardata1 = []\n",
    "lidardata2 = []\n",
    "for lasfile in matching_lasfiles.itertuples():\n",
    "    print(f\"    - las file: {lasfile.path}\")\n",
    "    array1 = get_lasdata(\n",
    "        lasfile.path, cellfile.xmin, cellfile.xmax, cellfile.ymin, cellfile.ymax\n",
    "    )\n",
    "    array1[\"lasfile\"] = pathlib.Path(lasfile.path).stem\n",
    "    array2 = get_lasground(\n",
    "        lasfile.path, cellfile.xmin, cellfile.xmax, cellfile.ymin, cellfile.ymax\n",
    "    )\n",
    "    array2[\"lasfile\"] = pathlib.Path(lasfile.path).stem\n",
    "    lidardata1.append(array1)\n",
    "    lidardata2.append(array2)\n",
    "lidardata1 = pd.concat(lidardata1, ignore_index=True)\n",
    "lidardata2 = pd.concat(lidardata2, ignore_index=True)\n",
    "xstep = (cellfile.xmax - cellfile.xmin) / imgRGB.shape[1]\n",
    "ystep = (cellfile.ymax - cellfile.ymin) / imgRGB.shape[0]\n",
    "lidardata1[\"m\"] = ((cellfile.ymax - lidardata1.Y) / ystep).astype(int)\n",
    "lidardata1[\"n\"] = ((lidardata1.X - cellfile.xmin) / xstep).astype(int)\n",
    "lidardata2[\"m\"] = ((cellfile.ymax - lidardata2.Y) / ystep).astype(int)\n",
    "lidardata2[\"n\"] = ((lidardata2.X - cellfile.xmin) / xstep).astype(int)\n",
    "\n",
    "pcd = open3d.geometry.PointCloud()\n",
    "pcd.points = open3d.utility.Vector3dVector(lidardata1[[\"X\", \"Y\", \"Z\"]].to_numpy())\n",
    "plane_model, inliers = pcd.segment_plane(\n",
    "    distance_threshold=0.01, ransac_n=3, num_iterations=1000\n",
    ")\n",
    "inlier_cloud = pcd.select_by_index(inliers)\n",
    "outlier_cloud = pcd.select_by_index(inliers, invert=True)\n",
    "\n",
    "lidardata3 = pd.DataFrame(np.asarray(outlier_cloud.points), columns=[\"X\", \"Y\", \"Z\"])\n",
    "lidardata3[\"m\"] = ((cellfile.ymax - lidardata3.Y) / ystep).astype(int)\n",
    "lidardata3[\"n\"] = ((lidardata3.X - cellfile.xmin) / xstep).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "  points_per_side (int or None): The number of points to be sampled\n",
    "    along one side of the image. The total number of points is\n",
    "    points_per_side**2. If None, 'point_grids' must provide explicit\n",
    "    point sampling.\n",
    "  points_per_batch (int): Sets the number of points run simultaneously\n",
    "    by the model. Higher numbers may be faster but use more GPU memory.\n",
    "  pred_iou_thresh (float): A filtering threshold in [0,1], using the\n",
    "    model's predicted mask quality.\n",
    "  stability_score_thresh (float): A filtering threshold in [0,1], using\n",
    "    the stability of the mask under changes to the cutoff used to binarize\n",
    "    the model's mask predictions.\n",
    "  stability_score_offset (float): The amount to shift the cutoff when\n",
    "    calculated the stability score.\n",
    "  box_nms_thresh (float): The box IoU cutoff used by non-maximal\n",
    "    suppression to filter duplicate masks.\n",
    "  crop_n_layers (int): If >0, mask prediction will be run again on\n",
    "    crops of the image. Sets the number of layers to run, where each\n",
    "    layer has 2**i_layer number of image crops.\n",
    "  crop_nms_thresh (float): The box IoU cutoff used by non-maximal\n",
    "    suppression to filter duplicate masks between different crops.\n",
    "  crop_overlap_ratio (float): Sets the degree to which crops overlap.\n",
    "    In the first crop layer, crops will overlap by this fraction of\n",
    "    the image length. Later layers with more crops scale down this overlap.\n",
    "  crop_n_points_downscale_factor (int): The number of points-per-side\n",
    "    sampled in layer n is scaled down by crop_n_points_downscale_factor**n.\n",
    "  point_grids (list(np.ndarray) or None): A list over explicit grids\n",
    "    of points used for sampling, normalized to [0,1]. The nth grid in the\n",
    "    list is used in the nth crop layer. Exclusive with points_per_side.\n",
    "  min_mask_region_area (int): If >0, postprocessing will be applied\n",
    "    to remove disconnected regions and holes in masks with area smaller\n",
    "    than min_mask_region_area. Requires opencv.\n",
    "  output_mode (str): The form masks are returned in. Can be 'binary_mask',\n",
    "    'uncompressed_rle', or 'coco_rle'. 'coco_rle' requires pycocotools.\n",
    "    For large resolutions, 'binary_mask' may consume large amounts of\n",
    "    memory.\n",
    "    points_per_side: Optional[int] = 32,\n",
    "    points_per_batch: int = 64,\n",
    "    pred_iou_thresh: float = 0.88,\n",
    "    stability_score_thresh: float = 0.95,\n",
    "    stability_score_offset: float = 1.0,\n",
    "    box_nms_thresh: float = 0.7,\n",
    "    crop_n_layers: int = 0,\n",
    "    crop_nms_thresh: float = 0.7,\n",
    "    crop_overlap_ratio: float = 512 / 1500,\n",
    "    crop_n_points_downscale_factor: int = 1,\n",
    "    point_grids: Optional[List[np.ndarray]] = None,\n",
    "    min_mask_region_area: int = 0,\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    del sam\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "import torch  # noqa: E402\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "hd = True\n",
    "device = \"cpu\"\n",
    "\n",
    "if hd:\n",
    "    from segment_anything_hq import SamAutomaticMaskGenerator, sam_model_registry\n",
    "\n",
    "    sam = sam_model_registry[\"vit_h\"](checkpoint=\"data/sam_weights/sam_hq_vit_h.pth\")\n",
    "    sam.to(device=device)\n",
    "else:\n",
    "    from segment_anything import SamAutomaticMaskGenerator, sam_model_registry\n",
    "\n",
    "    sam = sam_model_registry[\"vit_h\"](\n",
    "        checkpoint=\"data/sam_weights/sam_vit_h_4b8939.pth\"\n",
    "    )\n",
    "    sam.to(device=device)\n",
    "\n",
    "mask_generator = SamAutomaticMaskGenerator(\n",
    "    sam,\n",
    "    points_per_batch=32,  # nodig om geen OoM op de GPU te krijgen\n",
    ")\n",
    "\n",
    "plt.close(\"all\")\n",
    "for imgId in imgIds:\n",
    "    # COCO format img en annotation\n",
    "    img = coco.loadImgs(imgId)[0]\n",
    "\n",
    "    # Laad image in\n",
    "    imgPath = imgDir.joinpath(img[\"file_name\"])\n",
    "    imgRGB = skimage.io.imread(imgPath)\n",
    "    imgGray = skimage.io.imread(imgPath, as_gray=True)\n",
    "\n",
    "    # Laad annotation in\n",
    "    annIds = coco.getAnnIds(imgIds=img[\"id\"], catIds=catIds, iscrowd=None)\n",
    "    anns = coco.loadAnns(annIds)\n",
    "\n",
    "    # SAM mask\n",
    "    masks = mask_generator.generate(imgRGB)\n",
    "\n",
    "    # gesegmenteerd\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(imgGray, cmap=\"gray\")\n",
    "    coco.showAnns(anns, draw_bbox=True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # SAM\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(imgGray, cmap=\"gray\")\n",
    "    show_anns(masks)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "voorbeeld_path = pathlib.Path(\n",
    "    \"276114_20230714 MUG Hoorn Enkhuizen orthomosaic deel 1/2023-12-11 10_00_58.048/images\"\n",
    ")\n",
    "\n",
    "df_files = dict(name=[], img_path=[])\n",
    "for p in voorbeeld_path.iterdir():\n",
    "    if p.suffix == \".json\" or p.suffix == \".jpeg\":\n",
    "        if p.stem not in df_files[\"name\"]:\n",
    "            df_files[\"name\"].append(p.stem)\n",
    "        #         if p.suffix == \".json\":\n",
    "        #             df_files[\"segment_path\"].append(str(p))\n",
    "        #         else:\n",
    "        df_files[\"img_path\"].append(str(p))\n",
    "    else:\n",
    "        print(f\"unknown filetype {p.suffix=}, {p}\")\n",
    "df_files = pd.DataFrame(df_files)\n",
    "display(df_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.close(\"all\")\n",
    "\n",
    "# for i, row in enumerate(df_files.itertuples()):\n",
    "#     # Find tile bounds (X, Y) based on name\n",
    "#     tile1a = row.name.split(\"_\")[0]\n",
    "#     tile1b = int(row.name.split(\"_\")[-1])\n",
    "#     cellfile = df_tilebounds[\n",
    "#         (df_tilebounds.index == tile1b) & (df_tilebounds.name == tile1a)\n",
    "#     ].copy()\n",
    "#     assert len(cellfile) == 1\n",
    "#     cellfile = cellfile.iloc[0, :].copy()\n",
    "#     print(f\"  - {i + 1:>02d}/{len(df_files):>02d} rgb tile: '{tile1a}' ('{tile1b}')\")\n",
    "\n",
    "#     # Read image data\n",
    "#     imgdata = matplotlib.image.imread(row.img_path)\n",
    "\n",
    "#     # Read LIDAR data within the bounds of the image\n",
    "#     matching_lasfiles = df_las[df_las.intersects(cellfile.geometry)].copy()\n",
    "#     lidardata = []\n",
    "#     for lasfile in matching_lasfiles.itertuples():\n",
    "#         print(f\"    - las file: {lasfile.path}\")\n",
    "#         array = get_lasdata(\n",
    "#             lasfile.path, cellfile.xmin, cellfile.xmax, cellfile.ymin, cellfile.ymax\n",
    "#         )\n",
    "#         array[\"lasfile\"] = pathlib.Path(lasfile.path).stem\n",
    "#         lidardata.append(array)\n",
    "#     lidardata = pd.concat(lidardata, ignore_index=True)\n",
    "#     xstep = (cellfile.xmax - cellfile.xmin) / imgdata.shape[1]\n",
    "#     ystep = (cellfile.ymax - cellfile.ymin) / imgdata.shape[0]\n",
    "#     lidardata[\"m\"] = ((cellfile.ymax - lidardata.Y) / ystep).astype(int)\n",
    "#     lidardata[\"n\"] = ((lidardata.X - cellfile.xmin) / xstep).astype(int)\n",
    "\n",
    "#     # Read segmentation data\n",
    "#     lidardata_obj = []\n",
    "#     with open(row.segment_path) as f:\n",
    "#         # Read json data\n",
    "#         jsondata = json.load(f)\n",
    "\n",
    "#         # Read the bitmap masked data in the same shape as the imgdata\n",
    "#         full_mask = {\n",
    "#             \"opschot\": np.zeros((imgdata.shape[0], imgdata.shape[1]), dtype=bool),\n",
    "#             \"gras steenbekleding\": np.zeros(\n",
    "#                 (imgdata.shape[0], imgdata.shape[1]), dtype=bool\n",
    "#             ),\n",
    "#             \"twijfel opschot\": np.zeros(\n",
    "#                 (imgdata.shape[0], imgdata.shape[1]), dtype=bool\n",
    "#             ),\n",
    "#         }\n",
    "#         mask_bounds = []\n",
    "#         for obj in jsondata[\"annotation\"][\"objects\"]:\n",
    "#             cat_title = obj[\"classTitle\"]\n",
    "\n",
    "#             # Update complete mask\n",
    "#             bool_mask = base64_2_mask(obj[\"bitmap\"][\"data\"])\n",
    "#             n1, m1 = obj[\"bitmap\"][\"origin\"]\n",
    "#             m2 = m1 + bool_mask.shape[0]\n",
    "#             n2 = n1 + bool_mask.shape[1]\n",
    "#             full_mask[cat_title][m1:m2, n1:n2] = bool_mask\n",
    "\n",
    "#             # mask bounds\n",
    "#             bbox = shapely.box(n1, m1, n2, m2).boundary\n",
    "#             mask_bounds.append((cat_title, bbox))\n",
    "\n",
    "#             # relevant lidardata\n",
    "#             sublidar = lidardata[\n",
    "#                 (lidardata.m >= m1)\n",
    "#                 & (lidardata.m < m2)\n",
    "#                 & (lidardata.n >= n1)\n",
    "#                 & (lidardata.n < n2)\n",
    "#             ].copy()\n",
    "#             lidardata_obj.append(sublidar)\n",
    "\n",
    "#         mask_bounds = gpd.GeoDataFrame(\n",
    "#             pd.DataFrame(mask_bounds, columns=[\"mask_type\", \"geometry\"]),\n",
    "#             geometry=\"geometry\",\n",
    "#         )\n",
    "\n",
    "#     cat_int = {\n",
    "#         \"opschot\": 1,\n",
    "#         \"gras steenbekleding\": 2,\n",
    "#         \"twijfel opschot\": 3,\n",
    "#     }\n",
    "#     fig, axs = plt.subplots(nrows=2, ncols=2, figsize=(12, 8), dpi=100)\n",
    "\n",
    "#     # Show bounding boxes over image\n",
    "#     axs[0, 0].pcolormesh(imgdata)\n",
    "#     mask_bounds.plot(ax=axs[0, 0], column=\"mask_type\")\n",
    "#     axs[0, 0].invert_yaxis()\n",
    "\n",
    "#     # Show only the masked data with bounding boxes\n",
    "#     mask_bounds.plot(\n",
    "#         ax=axs[0, 1],\n",
    "#         column=\"mask_type\",\n",
    "#         legend=True,\n",
    "#         legend_kwds={\"loc\": \"center left\"},\n",
    "#     )\n",
    "#     for obj_title, arrmask in full_mask.items():\n",
    "#         if not arrmask.flatten().any():\n",
    "#             continue\n",
    "#         arrmask = np.tile(arrmask[:, :, np.newaxis], (1, 1, 3))\n",
    "#         arrmask = np.ma.masked_array(imgdata, ~arrmask)\n",
    "#         axs[0, 1].pcolormesh(arrmask)\n",
    "#     axs[0, 1].invert_yaxis()\n",
    "#     axs[0, 1].set_xlim(axs[0, 0].get_xlim())\n",
    "#     axs[0, 1].set_ylim(axs[0, 0].get_ylim())\n",
    "#     leg = axs[0, 1].get_legend()\n",
    "#     leg.set_bbox_to_anchor((1, 0.5))\n",
    "\n",
    "#     # Show lidar data with boxes\n",
    "#     mask_bounds.plot(ax=axs[0, 1], column=\"mask_type\")\n",
    "#     lidardata_plt = gpd.GeoDataFrame(\n",
    "#         lidardata, geometry=gpd.GeoSeries.from_xy(lidardata.n, lidardata.m)\n",
    "#     )\n",
    "#     lidardata_plt.plot(ax=axs[1, 0], column=\"Z\")\n",
    "#     axs[1, 0].invert_yaxis()\n",
    "#     axs[1, 0].set_xlim(axs[0, 0].get_xlim())\n",
    "#     axs[1, 0].set_ylim(axs[0, 0].get_ylim())\n",
    "\n",
    "#     mask_bounds.plot(\n",
    "#         ax=axs[1, 1],\n",
    "#         column=\"mask_type\",\n",
    "#         legend=True,\n",
    "#         legend_kwds={\"loc\": \"center left\"},\n",
    "#     )\n",
    "#     for lidarsubset in lidardata_obj:\n",
    "#         lidardata_plt = gpd.GeoDataFrame(\n",
    "#             lidarsubset, geometry=gpd.GeoSeries.from_xy(lidarsubset.n, lidarsubset.m)\n",
    "#         )\n",
    "#         lidardata_plt.plot(ax=axs[1, 1], column=\"Z\")\n",
    "#     axs[1, 1].invert_yaxis()\n",
    "#     axs[1, 1].set_xlim(axs[0, 0].get_xlim())\n",
    "#     axs[1, 1].set_ylim(axs[0, 0].get_ylim())\n",
    "#     leg = axs[1, 1].get_legend()\n",
    "#     leg.set_bbox_to_anchor((1, 0.5))\n",
    "\n",
    "#     fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
