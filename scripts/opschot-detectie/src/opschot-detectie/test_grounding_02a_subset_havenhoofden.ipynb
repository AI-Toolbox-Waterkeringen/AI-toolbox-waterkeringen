{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174e74d4-2e09-48a0-81d3-1869dbd3ac5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.collections import PolyCollection\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import PIL\n",
    "from pathlib import Path\n",
    "import tqdm\n",
    "import rasterio.features\n",
    "import shapely.geometry\n",
    "import glob\n",
    "\n",
    "# COCO tools\n",
    "import pycocotools.mask\n",
    "from pycocotools.coco import COCO\n",
    "\n",
    "# # Recognize Anything Model & Tag2Text\n",
    "# from ram.models import ram_plus\n",
    "# from ram import inference_ram\n",
    "# import torchvision.transforms as TS\n",
    "\n",
    "# Grounding Dino\n",
    "from groundingdino.util.inference import load_model\n",
    "import groundingdino.datasets.transforms as T\n",
    "from groundingdino.util.utils import get_phrases_from_posmap\n",
    "\n",
    "# Segment anything\n",
    "from segment_anything_hq import (\n",
    "    SamPredictor as SamPredictor_hq,\n",
    "    sam_model_registry as sam_model_registry_hq,\n",
    ")\n",
    "from segment_anything import SamPredictor, sam_model_registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93aa4a0-a281-4c27-9c67-483fd46ecf15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hydra import initialize, compose\n",
    "\n",
    "with initialize(\"config\", version_base=None):\n",
    "    cfg = compose(\"config.yaml\")\n",
    "\n",
    "print(cfg)\n",
    "# Load grounding dino model\n",
    "dino_model = load_model(\n",
    "    cfg.GROUNDING_DINO_CONFIG_PATH,\n",
    "    cfg.GROUNDING_DINO_CHECKPOINT_PATH,\n",
    "    device=cfg.DEVICE,\n",
    ")\n",
    "\n",
    "# Segment Anything Model (SAM)\n",
    "\n",
    "if cfg.USE_SAM_HQ:\n",
    "    print(\"Initialize SAM-HQ Predictor\")\n",
    "    sam = sam_model_registry_hq[cfg.SAM_HQ_ENCODER_VERSION](\n",
    "        checkpoint=cfg.SAM_HQ_CHECKPOINT_PATH\n",
    "    ).to(device=cfg.DEVICE)\n",
    "    sam_predictor = SamPredictor_hq(sam)\n",
    "else:\n",
    "    sam = sam_model_registry[cfg.SAM_ENCODER_VERSION](\n",
    "        checkpoint=cfg.SAM_CHECKPOINT_PATH\n",
    "    ).to(device=cfg.DEVICE)\n",
    "    sam_predictor = SamPredictor(sam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1062d5ea-baf3-4431-ac86-c0cd3465a75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_tile_bounds(root_tilepath, concat=True):\n",
    "    \"\"\"\n",
    "    Recursively search through directories starting from root_tilepath to find and optionally concatenate\n",
    "    geospatial data files (.gpkg) that include 'cells_intersect' in their filename.\n",
    "\n",
    "    Parameters:\n",
    "    - root_tilepath (str or pathlib.Path): The root directory path where the search for tile files begins.\n",
    "    - concat (bool, optional): If True, concatenates all found geospatial data into a single DataFrame.\n",
    "                               If False, returns a list of DataFrames. Default is True.\n",
    "\n",
    "    Returns:\n",
    "    - pandas.DataFrame or list of geopandas.GeoDataFrame: The concatenated DataFrame of all files if `concat=True`,\n",
    "      or a list of DataFrames for each file if `concat=False`.\n",
    "\n",
    "    \"\"\"\n",
    "    cell_files = []\n",
    "    for p in Path(str(root_tilepath)).iterdir():\n",
    "        if p.is_dir():\n",
    "            cell_files += find_tile_bounds(p, concat=False)\n",
    "        elif p.is_file() and p.suffix == \".gpkg\" and \"tiles_intersect\" in p.stem:\n",
    "            df = gpd.read_file(p)\n",
    "            df[\"name\"] = p.stem.replace(\"_tiles_intersects\", \"\")\n",
    "            cell_files.append(df.copy())\n",
    "\n",
    "    if concat:\n",
    "        cell_files = pd.concat(cell_files)\n",
    "\n",
    "    return cell_files\n",
    "\n",
    "\n",
    "# tilebounds\n",
    "df_tilebounds = find_tile_bounds(Path(cfg.disk_path) / \"tile_dataset_havenhoofden\")\n",
    "df_tilebounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ba5522-6863-4740-81c2-ccd527889d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = Path(cfg.disk_path) / \"output_havenhoofden\"\n",
    "if not out_dir.exists():\n",
    "    out_dir.mkdir()\n",
    "else:\n",
    "    print(f\"Directory {out_dir} already exists!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46904f65-b22f-41bf-bbf0-483e01c5c22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Path(cfg.disk_path) / \"tile_dataset_havenhoofden\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1014e081-1443-4358-b16f-d97f5b8cd776",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDirs = [\n",
    "    Path(p)\n",
    "    for p in glob.glob(\n",
    "        str(\n",
    "            Path(cfg.disk_path)\n",
    "            / \"tile_dataset_havenhoofden\"\n",
    "            / \"20230714 MUG Medemblik Den Oever orthomosaic deel *\"\n",
    "        )\n",
    "    )\n",
    "]\n",
    "\n",
    "for dataDir in dataDirs:\n",
    "    print(dataDir)\n",
    "\n",
    "    projName = dataDir.stem\n",
    "\n",
    "    df_pred_shapes = dict(\n",
    "        category=[],\n",
    "        confidence=[],\n",
    "        tile_path=[],\n",
    "        project_name=[],\n",
    "        tile_fname=[],\n",
    "        geometry=[],\n",
    "    )\n",
    "\n",
    "    imgPaths = glob.glob(str(dataDir / \"tiles_havenhoofden\" / \"*.jpeg\"))\n",
    "\n",
    "    for imgPath in tqdm.tqdm(imgPaths):\n",
    "        print(imgPath)\n",
    "\n",
    "        # Load image\n",
    "        image_pil, image = load_image(imgPath)\n",
    "\n",
    "        # Tags\n",
    "        if cfg.fixed_tags:\n",
    "            tags = \",\".join(cfg.fixed_tags)\n",
    "        else:\n",
    "            # Find tags with RAM\n",
    "            ram_model = ram_model.to(cfg.DEVICE)\n",
    "            raw_image = image_pil.resize((384, 384))\n",
    "            raw_image = transform(raw_image).unsqueeze(0).to(cfg.DEVICE)\n",
    "            res = inference_ram(raw_image, ram_model)\n",
    "            tags = res[0].replace(\" |\", \",\")\n",
    "\n",
    "        # Find bounding boxes with grounding dino\n",
    "        boxes_filt, scores, pred_phrases = get_grounding_output(\n",
    "            dino_model,\n",
    "            image,\n",
    "            tags,\n",
    "            DINO_BOX_THRESHOLD,\n",
    "            DINO_TEXT_THRESHOLD,\n",
    "            device=DEVICE,\n",
    "        )\n",
    "\n",
    "        # Resize boxes\n",
    "        size = image_pil.size\n",
    "        H, W = size[1], size[0]\n",
    "        for i in range(boxes_filt.size(0)):\n",
    "            boxes_filt[i] = boxes_filt[i] * torch.Tensor([W, H, W, H])\n",
    "            boxes_filt[i][:2] -= boxes_filt[i][2:] / 2\n",
    "            boxes_filt[i][2:] += boxes_filt[i][:2]\n",
    "\n",
    "        # use NMS to handle overlapped boxes\n",
    "        boxes_filt = boxes_filt.cpu()\n",
    "        nms_idx = (\n",
    "            torchvision.ops.nms(boxes_filt, scores, IOU_THRESHOLD).numpy().tolist()\n",
    "        )\n",
    "        if DO_IOU_MERGE:\n",
    "            boxes_filt_clean = boxes_filt[nms_idx]\n",
    "            pred_phrases_clean = [pred_phrases[idx] for idx in nms_idx]\n",
    "            # print(f\"NMS: before {boxes_filt.shape[0]} boxes, after {boxes_filt_clean.shape[0]} boxes\")\n",
    "        else:\n",
    "            boxes_filt_clean = boxes_filt\n",
    "            pred_phrases_clean = pred_phrases\n",
    "\n",
    "        # Segment objects with SAM\n",
    "        image_np = np.array(image_pil)\n",
    "        sam_predictor.set_image(image_np)\n",
    "        transformed_boxes = sam_predictor.transform.apply_boxes_torch(\n",
    "            boxes_filt_clean, image_np.shape[:2]\n",
    "        ).to(DEVICE)\n",
    "        masks, _, _ = sam_predictor.predict_torch(\n",
    "            point_coords=None,\n",
    "            point_labels=None,\n",
    "            boxes=transformed_boxes.to(DEVICE),\n",
    "            multimask_output=False,\n",
    "        )\n",
    "\n",
    "        # Find tile bounds (X, Y) based on name\n",
    "        imgName = Path(imgPath).stem\n",
    "        tile1a = imgName.split(\"_\")[0]\n",
    "        tile1b = int(imgName.split(\"_\")[-1])\n",
    "        cellfile = df_tilebounds[\n",
    "            (df_tilebounds.index == tile1b) & (df_tilebounds.name == tile1a)\n",
    "        ].copy()\n",
    "        assert len(cellfile) == 1\n",
    "        cellfile = cellfile.iloc[0, :].copy()\n",
    "        xstep = (cellfile.xmax - cellfile.xmin) / image_np.shape[1]\n",
    "        ystep = (cellfile.ymax - cellfile.ymin) / image_np.shape[0]\n",
    "\n",
    "        # eventueel nog geometry van cellfile ipv tabel,\n",
    "        # eventueel test via inladen tiff\n",
    "\n",
    "        affine = [xstep, 0, cellfile.xmin, 0, -ystep, cellfile.ymax, 0, 0, 1]\n",
    "\n",
    "        # SAM masks\n",
    "        assert len(pred_phrases_clean) == len(masks)\n",
    "        shapes, titles = [], []\n",
    "        for cat_title, mask in zip(pred_phrases_clean, masks):\n",
    "            mask = mask.cpu().numpy()\n",
    "            cat_shapes = rasterio.features.shapes(\n",
    "                mask.astype(np.uint8), mask=mask, connectivity=4, transform=affine\n",
    "            )\n",
    "            for shape, _ in cat_shapes:\n",
    "                title, confidence = cat_title.replace(\")\", \"\").split(\"(\")\n",
    "                shape = shapely.geometry.shape(shape).simplify(\n",
    "                    0.01, preserve_topology=True\n",
    "                )\n",
    "                if shape.area > 0.01:\n",
    "                    df_pred_shapes[\"category\"].append(title)\n",
    "                    df_pred_shapes[\"confidence\"].append(confidence)\n",
    "                    df_pred_shapes[\"geometry\"].append(shape)\n",
    "\n",
    "                    df_pred_shapes[\"tile_path\"].append(str(imgPath))\n",
    "                    df_pred_shapes[\"tile_fname\"].append(Path(imgPath).stem)\n",
    "                    df_pred_shapes[\"project_name\"].append(projName)\n",
    "\n",
    "    df_pred_shapes = gpd.GeoDataFrame(df_pred_shapes, crs=\"epsg:28992\")\n",
    "    if USE_SAM_HQ:\n",
    "        df_pred_shapes.to_file(out_dir / f\"fix_tags_hq_{projName}_havenhoofden.gpkg\")\n",
    "    else:\n",
    "        df_pred_shapes.to_file(out_dir / f\"fix_tags_{projName}_havenhoofden.gpkg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c0a3b7-51cd-43ba-afe5-4d6c6a28dc80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9d268f-1ea1-4a72-9aad-a61c6e5f629e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e42c016-5903-454b-9d3c-89d54e3d2433",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
