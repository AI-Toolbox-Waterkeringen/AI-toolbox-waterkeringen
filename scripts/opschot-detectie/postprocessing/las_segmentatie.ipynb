{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59932af-c5cb-4396-a6d2-953f569c6d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdal\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image\n",
    "import pathlib\n",
    "import subprocess\n",
    "import json\n",
    "import tqdm.auto as tqdm\n",
    "import shapely.geometry\n",
    "import numpy as np\n",
    "from pycocotools.coco import COCO\n",
    "import skimage.io\n",
    "import open3d\n",
    "from open3d.web_visualizer import draw\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import zlib\n",
    "import base64\n",
    "import io\n",
    "from PIL import Image\n",
    "\n",
    "print(f\"Using pdal version {pdal.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b13220-1925-44e1-9586-c7a29be8c86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_las_bounds(lasfolder):\n",
    "    \"\"\" \"\"\"\n",
    "    lasfiles = [p for p in pathlib.Path(lasfolder).iterdir() if p.suffix == \".laz\"]\n",
    "    df_las = []\n",
    "    for p in tqdm.tqdm(lasfiles):\n",
    "        # decode stdout from bytestring and convert to a dictionary\n",
    "        result = subprocess.run(\n",
    "            [\"pdal\", \"info\", str(p)], stderr=subprocess.PIPE, stdout=subprocess.PIPE\n",
    "        )\n",
    "        json_result = json.loads(result.stdout.decode())\n",
    "        maxx, maxy, maxz, minx, miny, minz = json_result[\"stats\"][\"bbox\"][\"native\"][\n",
    "            \"bbox\"\n",
    "        ].values()\n",
    "        geom = shapely.geometry.box(minx, miny, maxx, maxy)\n",
    "        df_las.append((p.stem, str(p), maxx, maxy, maxz, minx, miny, minz, geom))\n",
    "    df_las = pd.DataFrame(\n",
    "        df_las,\n",
    "        columns=[\n",
    "            \"name\",\n",
    "            \"path\",\n",
    "            \"maxx\",\n",
    "            \"maxy\",\n",
    "            \"maxz\",\n",
    "            \"minx\",\n",
    "            \"miny\",\n",
    "            \"minz\",\n",
    "            \"geometry\",\n",
    "        ],\n",
    "    )\n",
    "    df_las = gpd.GeoDataFrame(df_las, geometry=\"geometry\", crs=\"epsg:28992\")\n",
    "    return df_las\n",
    "\n",
    "\n",
    "def find_tile_bounds(root_tilepath, concat=True):\n",
    "    cell_files = []\n",
    "    for p in pathlib.Path(root_tilepath).iterdir():\n",
    "        if p.is_dir():\n",
    "            cell_files += find_tile_bounds(p, concat=False)\n",
    "        elif p.is_file() and p.suffix == \".gpkg\" and \"cells_intersect\" in p.stem:\n",
    "            df = gpd.read_file(p)\n",
    "            df[\"name\"] = p.stem.replace(\"_cells_intersects\", \"\")\n",
    "            cell_files.append(df.copy())\n",
    "    if concat:\n",
    "        cell_files = pd.concat(cell_files)\n",
    "    return cell_files\n",
    "\n",
    "\n",
    "def get_lasdata(las_file, xmin, xmax, ymin, ymax):\n",
    "    jsondata = f\"\"\"\n",
    "    [\n",
    "        \"{lasfile.path}\",\n",
    "        {{\n",
    "            \"type\":\"filters.expression\",\n",
    "            \"expression\":\"(X >= {xmin} && X <= {xmax} && Y >= {ymin} && Y <= {ymax})\"\n",
    "        }}\n",
    "    ]\n",
    "    \"\"\"\n",
    "    pipeline = pdal.Pipeline(jsondata)\n",
    "    count = pipeline.execute()\n",
    "    arrays = pipeline.arrays\n",
    "    assert len(arrays) == 1\n",
    "    #         metadata = pipeline.metadata\n",
    "    #         log = pipeline.log\n",
    "    arrays = pd.DataFrame(arrays[0])\n",
    "    return arrays\n",
    "\n",
    "\n",
    "def get_lasground(las_file, xmin, xmax, ymin, ymax):\n",
    "    jsondata = f\"\"\"\n",
    "    [\n",
    "        \"{lasfile.path}\",\n",
    "        {{\n",
    "            \"type\":\"filters.expression\",\n",
    "            \"expression\":\"(X >= {xmin} && X <= {xmax} && Y >= {ymin} && Y <= {ymax})\"\n",
    "        }},\n",
    "        {{\n",
    "            \"type\":\"filters.assign\",\n",
    "            \"assignment\":\"Classification[:]=0\"\n",
    "        }},\n",
    "        {{\n",
    "            \"type\":\"filters.smrf\",\n",
    "            \"scalar\": 1.2,\n",
    "            \"slope\": 0.2,\n",
    "            \"threshold\": 0.45,\n",
    "            \"window\": 16.0\n",
    "        }}\n",
    "    ]\n",
    "    \"\"\"\n",
    "    pipeline = pdal.Pipeline(jsondata)\n",
    "    count = pipeline.execute()\n",
    "    arrays = pipeline.arrays\n",
    "    assert len(arrays) == 1\n",
    "    #         metadata = pipeline.metadata\n",
    "    #         log = pipeline.log\n",
    "    arrays = pd.DataFrame(arrays[0])\n",
    "    return arrays\n",
    "\n",
    "\n",
    "def base64_2_mask(s):\n",
    "    z = zlib.decompress(base64.b64decode(s))\n",
    "    n = np.frombuffer(z, np.uint8)\n",
    "    mask = cv2.imdecode(n, cv2.IMREAD_UNCHANGED)[:, :, 3].astype(bool)\n",
    "    return mask\n",
    "\n",
    "\n",
    "def mask_2_base64(mask):\n",
    "    img_pil = Image.fromarray(np.array(mask, dtype=np.uint8))\n",
    "    img_pil.putpalette([0, 0, 0, 255, 255, 255])\n",
    "    bytes_io = io.BytesIO()\n",
    "    img_pil.save(bytes_io, format=\"PNG\", transparency=0, optimize=0)\n",
    "    bytes = bytes_io.getvalue()\n",
    "    return base64.b64encode(zlib.compress(bytes)).decode(\"utf-8\")\n",
    "\n",
    "\n",
    "def get_overlap_laz(gdf_laz, gdf_tiles):\n",
    "    \"\"\" \"\"\"\n",
    "    # Create a spatial index for gdf2 to efficiently query overlaps\n",
    "    sindex_gdf_tiles = gdf_tiles.sindex\n",
    "    # Use a list comprehension with any() to find overlaps using the spatial index\n",
    "    overlaps_mask = [\n",
    "        any(\n",
    "            gdf_tiles.iloc[\n",
    "                sindex_gdf_tiles.query(geometry, predicate=\"intersects\")\n",
    "            ].geometry.intersects(geometry)\n",
    "        )\n",
    "        for geometry in gdf_laz.geometry\n",
    "    ]\n",
    "    # Apply the mask to gdf1 to filter rows that overlap with gdf2\n",
    "    overlapping_gdf = gdf_laz[overlaps_mask]\n",
    "    return overlapping_gdf\n",
    "\n",
    "\n",
    "def zip_lasfiles(gdf_las):\n",
    "    # List of file paths you want to include in the zip file\n",
    "    files_to_zip = list(gdf_las.path)\n",
    "    zip_file_name = \"lasfiles.zip\"\n",
    "    # Create a zip file\n",
    "    with zipfile.ZipFile(zip_file_name, \"w\", zipfile.ZIP_DEFLATED) as zipf:\n",
    "        for file in files_to_zip:\n",
    "            # Add each file to the zip file\n",
    "            zipf.write(file, arcname=file.split(\"/\")[-1])\n",
    "    print(f\"Created zip file {zip_file_name} containing {len(files_to_zip)} files.\")\n",
    "\n",
    "\n",
    "def show_anns(anns):\n",
    "    if len(anns) == 0:\n",
    "        return\n",
    "    sorted_anns = sorted(anns, key=(lambda x: x[\"area\"]), reverse=True)\n",
    "    ax = plt.gca()\n",
    "    ax.set_autoscale_on(False)\n",
    "\n",
    "    img = np.ones(\n",
    "        (\n",
    "            sorted_anns[0][\"segmentation\"].shape[0],\n",
    "            sorted_anns[0][\"segmentation\"].shape[1],\n",
    "            4,\n",
    "        )\n",
    "    )\n",
    "    img[:, :, 3] = 0\n",
    "    for ann in sorted_anns:\n",
    "        m = ann[\"segmentation\"]\n",
    "        color_mask = np.concatenate([np.random.random(3), [0.35]])\n",
    "        img[m] = color_mask\n",
    "    ax.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7f2846-38ed-458e-ad4b-7cb7e2fe2d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config\n",
    "path_lasdata = pathlib.Path(\"data\")\n",
    "path_lasbounds = pathlib.Path(\"las_bounds_selected.gpkg\")\n",
    "path_tifftiles = pathlib.Path(\"data/tile_dataset\")\n",
    "debug = True\n",
    "# path with geometry of las files (bounding box)\n",
    "if not path_lasbounds.exists():\n",
    "    gdf_las = make_las_bounds(path_lasdata)\n",
    "    gdf_las.to_file(path_lasbounds)\n",
    "else:\n",
    "    print(f\"File: '{path_lasbounds}' already exists!\")\n",
    "\n",
    "# geodataframe with geometries of las files\n",
    "gdf_las = gpd.read_file(path_lasbounds)\n",
    "print(f\"Found {len(gdf_las)} las files\")\n",
    "\n",
    "# geodataframe with geometries of tiles\n",
    "gdf_tilebounds = find_tile_bounds(path_tifftiles)\n",
    "gdf_tilebounds_selected = gdf_tilebounds.sjoin(gdf_las, how=\"inner\")\n",
    "\n",
    "if debug:\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(12, 5))\n",
    "    gdf_las.plot(ax=ax, edgecolor=\"black\", facecolor=\"None\", linewidth=1)\n",
    "    gdf_tilebounds_selected.plot(ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f0f5ef-825e-4c3b-ac13-132f87d48531",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "overlapping_gdf = get_overlap_laz(gdf_las, gdf_tilebounds_selected.iloc[idx : idx + 1])\n",
    "overlapping_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd50628-24b6-471d-9418-a2893c65402c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(16, 12))\n",
    "gdf_las.plot(ax=ax, facecolor=\"white\", edgecolor=\"black\")\n",
    "overlapping_gdf.plot(ax=ax, facecolor=\"white\", edgecolor=\"red\")\n",
    "gdf_tilebounds_selected.plot(ax=ax, facecolor=\"white\", edgecolor=\"blue\")\n",
    "gdf_tilebounds_selected.iloc[idx : idx + 1].plot(\n",
    "    ax=ax, facecolor=\"white\", edgecolor=\"green\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498ce496-1a4b-4113-883e-a3d007127762",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "###### aanpak ######\n",
    "\n",
    "# 1. per tile, haal laz data op en sla op als copc laz, voeg bestandsnaam toe aan tekstbestand\n",
    "# 2. maak een vpc file van alle bestanden die in het tekstbestand staan\n",
    "\n",
    "\n",
    "def tile_to_copc(gdf_laz, xmin, xmax, ymin, ymax):\n",
    "    \"\"\"\n",
    "    Gets LiDAR point cloud data from file, selects data within tile and exports as Cloud Optimized Point Cloud format\n",
    "    \"\"\"\n",
    "    abs_fp_out = \"test.copc\"\n",
    "    jsondata = f\"\"\"\n",
    "    [\n",
    "        {gdf_laz.iloc[0].path},\n",
    "        {\"type\":\"filters.expression\"},\n",
    "        {\"expression\":\"(X >= {xmin} && X <= {xmax} && Y >= {ymin} && Y <= {ymax})\"}, \n",
    "        {\"type\": \"writers.copc\", filename': {abs_fp_out}}\n",
    "        \n",
    "    ]\"\"\"\n",
    "    print(jsondata)\n",
    "    pipeline = pdal.Pipeline(jsondata)\n",
    "    count = pipeline.execute()\n",
    "    return\n",
    "\n",
    "\n",
    "tile_to_copc(\n",
    "    overlapping_gdf,\n",
    "    gdf_tilebounds_selected.iloc[idx][\"xmin\"],\n",
    "    gdf_tilebounds_selected.iloc[idx][\"xmax\"],\n",
    "    gdf_tilebounds_selected.iloc[idx][\"ymin\"],\n",
    "    gdf_tilebounds_selected.iloc[idx][\"ymax\"],\n",
    ")\n",
    "\n",
    "get_lasdata(las_file, xmin, xmax, ymin, ymax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b00e546-80ed-4e44-aafd-08c9b1bb8a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 47\n",
    "overlapping_gdf = get_overlap_laz(gdf_las, gdf_tilebounds_selected.iloc[idx : idx + 1])\n",
    "fig, ax = plt.subplots(1, 1, figsize=(25, 20))\n",
    "gdf_las.plot(ax=ax, facecolor=\"white\", edgecolor=\"black\")\n",
    "overlapping_gdf.plot(ax=ax, facecolor=\"white\", edgecolor=\"red\")\n",
    "gdf_tilebounds_selected.plot(ax=ax, facecolor=\"white\", edgecolor=\"blue\")\n",
    "gdf_tilebounds_selected.iloc[idx : idx + 1].plot(\n",
    "    ax=ax, facecolor=\"white\", edgecolor=\"green\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594690e6-efca-4536-ba5e-3fba96b01d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDir = pathlib.Path(\n",
    "    \"276114_20230714 MUG Hoorn Enkhuizen orthomosaic deel 1/2023-12-11 10_00_58.048\"\n",
    ")\n",
    "dataDir = pathlib.Path(\n",
    "    \"data/supervisely/277426_20230714 MUG Hoorn Enkhuizen orthomosaic deel 6/2023-12-11 12_52_14.810\"\n",
    ")\n",
    "annFile = dataDir.joinpath(\"annotations/instances.json\")\n",
    "imgDir = dataDir.joinpath(\"images\")\n",
    "\n",
    "# initialize COCO api for instance annotations\n",
    "coco = COCO(annFile)\n",
    "print(\"\")\n",
    "\n",
    "cats = coco.loadCats(coco.getCatIds())\n",
    "nms = [cat[\"name\"] for cat in cats]\n",
    "print(\"COCO categories: \\n{}\\n\".format(\" \".join(nms)))\n",
    "\n",
    "# nms = set([cat[\"supercategory\"] for cat in cats])\n",
    "# print(\"COCO supercategories: \\n{}\".format(\" \".join(nms)))\n",
    "\n",
    "catIds = coco.getCatIds(catNms=[\"twijfel opschot\", \"opschot\"])\n",
    "# imgIds = coco.getImgIds(catIds=catIds)\n",
    "imgIds = coco.getImgIds()\n",
    "\n",
    "plt.close(\"all\")\n",
    "for i, imgId in enumerate(imgIds):\n",
    "    # Find tile bounds (X, Y) based on name\n",
    "    imgName = \".\".join(coco.imgs[imgId][\"file_name\"].split(\".\")[:-1])\n",
    "    tile1a = imgName.split(\"_\")[0]\n",
    "    tile1b = int(imgName.split(\"_\")[-1])\n",
    "    cellfile = gdf_tilebounds[\n",
    "        (gdf_tilebounds.index == tile1b) & (gdf_tilebounds.name == tile1a)\n",
    "    ].copy()\n",
    "    assert len(cellfile) == 1\n",
    "    cellfile = cellfile.iloc[0, :].copy()\n",
    "    print(f\"  - {i+1:>02d}/{len(imgIds):>02d} rgb tile: '{tile1a}' ('{tile1b}')\")\n",
    "\n",
    "    # COCO format img en annotation\n",
    "    img = coco.loadImgs(imgId)[0]\n",
    "\n",
    "    # Laad image in\n",
    "    imgPath = imgDir.joinpath(img[\"file_name\"])\n",
    "    imgRGB = skimage.io.imread(imgPath)\n",
    "    imgGray = skimage.io.imread(imgPath, as_gray=True)\n",
    "\n",
    "    # Laad annotation in\n",
    "    annIds = coco.getAnnIds(imgIds=img[\"id\"], catIds=catIds, iscrowd=None)\n",
    "    anns = coco.loadAnns(annIds)\n",
    "\n",
    "    # Read LIDAR data within the bounds of the image\n",
    "    matching_lasfiles = gdf_las[gdf_las.intersects(cellfile.geometry)].copy()\n",
    "    lidardata1 = []\n",
    "    lidardata2 = []\n",
    "    for lasfile in matching_lasfiles.itertuples():\n",
    "        print(f\"    - las file: {lasfile.path}\")\n",
    "        array1 = get_lasdata(\n",
    "            lasfile.path, cellfile.xmin, cellfile.xmax, cellfile.ymin, cellfile.ymax\n",
    "        )\n",
    "        array1[\"lasfile\"] = pathlib.Path(lasfile.path).stem\n",
    "        array2 = get_lasground(\n",
    "            lasfile.path, cellfile.xmin, cellfile.xmax, cellfile.ymin, cellfile.ymax\n",
    "        )\n",
    "        array2[\"lasfile\"] = pathlib.Path(lasfile.path).stem\n",
    "        lidardata1.append(array1)\n",
    "        lidardata2.append(array2)\n",
    "    lidardata1 = pd.concat(lidardata1, ignore_index=True)\n",
    "    lidardata2 = pd.concat(lidardata2, ignore_index=True)\n",
    "    xstep = (cellfile.xmax - cellfile.xmin) / imgRGB.shape[1]\n",
    "    ystep = (cellfile.ymax - cellfile.ymin) / imgRGB.shape[0]\n",
    "    lidardata1[\"m\"] = ((cellfile.ymax - lidardata1.Y) / ystep).astype(int)\n",
    "    lidardata1[\"n\"] = ((lidardata1.X - cellfile.xmin) / xstep).astype(int)\n",
    "    lidardata2[\"m\"] = ((cellfile.ymax - lidardata2.Y) / ystep).astype(int)\n",
    "    lidardata2[\"n\"] = ((lidardata2.X - cellfile.xmin) / xstep).astype(int)\n",
    "\n",
    "    pcd = open3d.geometry.PointCloud()\n",
    "    pcd.points = open3d.utility.Vector3dVector(lidardata1[[\"X\", \"Y\", \"Z\"]].to_numpy())\n",
    "    plane_model, inliers = pcd.segment_plane(\n",
    "        distance_threshold=0.01, ransac_n=3, num_iterations=1000\n",
    "    )\n",
    "    inlier_cloud = pcd.select_by_index(inliers)\n",
    "    outlier_cloud = pcd.select_by_index(inliers, invert=True)\n",
    "\n",
    "    lidardata3 = pd.DataFrame(np.asarray(outlier_cloud.points), columns=[\"X\", \"Y\", \"Z\"])\n",
    "    lidardata3[\"m\"] = ((cellfile.ymax - lidardata3.Y) / ystep).astype(int)\n",
    "    lidardata3[\"n\"] = ((lidardata3.X - cellfile.xmin) / xstep).astype(int)\n",
    "\n",
    "    # Make plot\n",
    "    fig, axs = plt.subplots(figsize=(15, 5), ncols=3)\n",
    "    plt.sca(axs[0])\n",
    "    plt.imshow(imgGray, cmap=\"gray\")\n",
    "    coco.showAnns(anns, draw_bbox=True)\n",
    "\n",
    "    lp1 = gpd.GeoDataFrame(\n",
    "        lidardata1, geometry=gpd.GeoSeries.from_xy(lidardata1.n, lidardata1.m)\n",
    "    )\n",
    "    lp2 = gpd.GeoDataFrame(\n",
    "        lidardata2, geometry=gpd.GeoSeries.from_xy(lidardata2.n, lidardata2.m)\n",
    "    )\n",
    "    lp3 = gpd.GeoDataFrame(\n",
    "        lidardata3, geometry=gpd.GeoSeries.from_xy(lidardata3.n, lidardata3.m)\n",
    "    )\n",
    "    #     lp1.plot(ax=axs[1], column=\"Z\")\n",
    "    lp1[(lp1.NumberOfReturns > 1) & (lp1.ReturnNumber == 1)].plot(ax=axs[1], column=\"Z\")\n",
    "    #     lp2[lp2.Classification != 2].plot(ax=axs[2], column=\"Z\")\n",
    "    lp3.plot(ax=axs[2], column=\"Z\")\n",
    "\n",
    "    for ax in axs[1:]:\n",
    "        ax.invert_yaxis()\n",
    "        ax.set_xlim(axs[0].get_xlim())\n",
    "        ax.set_ylim(axs[0].get_ylim())\n",
    "    for ax in axs:\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "    if i >= 9:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc63284-e4ae-40c9-b617-6049d55b4607",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read LIDAR data within the bounds of the image\n",
    "matching_lasfiles = gdf_las[gdf_las.intersects(cellfile.geometry)].copy()\n",
    "lidardata1 = []\n",
    "lidardata2 = []\n",
    "for lasfile in matching_lasfiles.itertuples():\n",
    "    print(f\"    - las file: {lasfile.path}\")\n",
    "    array1 = get_lasdata(\n",
    "        lasfile.path, cellfile.xmin, cellfile.xmax, cellfile.ymin, cellfile.ymax\n",
    "    )\n",
    "    array1[\"lasfile\"] = pathlib.Path(lasfile.path).stem\n",
    "    array2 = get_lasground(\n",
    "        lasfile.path, cellfile.xmin, cellfile.xmax, cellfile.ymin, cellfile.ymax\n",
    "    )\n",
    "    array2[\"lasfile\"] = pathlib.Path(lasfile.path).stem\n",
    "    lidardata1.append(array1)\n",
    "    lidardata2.append(array2)\n",
    "lidardata1 = pd.concat(lidardata1, ignore_index=True)\n",
    "lidardata2 = pd.concat(lidardata2, ignore_index=True)\n",
    "xstep = (cellfile.xmax - cellfile.xmin) / imgRGB.shape[1]\n",
    "ystep = (cellfile.ymax - cellfile.ymin) / imgRGB.shape[0]\n",
    "lidardata1[\"m\"] = ((cellfile.ymax - lidardata1.Y) / ystep).astype(int)\n",
    "lidardata1[\"n\"] = ((lidardata1.X - cellfile.xmin) / xstep).astype(int)\n",
    "lidardata2[\"m\"] = ((cellfile.ymax - lidardata2.Y) / ystep).astype(int)\n",
    "lidardata2[\"n\"] = ((lidardata2.X - cellfile.xmin) / xstep).astype(int)\n",
    "\n",
    "pcd = open3d.geometry.PointCloud()\n",
    "pcd.points = open3d.utility.Vector3dVector(lidardata1[[\"X\", \"Y\", \"Z\"]].to_numpy())\n",
    "plane_model, inliers = pcd.segment_plane(\n",
    "    distance_threshold=0.01, ransac_n=3, num_iterations=1000\n",
    ")\n",
    "inlier_cloud = pcd.select_by_index(inliers)\n",
    "outlier_cloud = pcd.select_by_index(inliers, invert=True)\n",
    "\n",
    "lidardata3 = pd.DataFrame(np.asarray(outlier_cloud.points), columns=[\"X\", \"Y\", \"Z\"])\n",
    "lidardata3[\"m\"] = ((cellfile.ymax - lidardata3.Y) / ystep).astype(int)\n",
    "lidardata3[\"n\"] = ((lidardata3.X - cellfile.xmin) / xstep).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ab8fea-8d81-4c4a-bcee-dbe9c74984b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "  points_per_side (int or None): The number of points to be sampled\n",
    "    along one side of the image. The total number of points is\n",
    "    points_per_side**2. If None, 'point_grids' must provide explicit\n",
    "    point sampling.\n",
    "  points_per_batch (int): Sets the number of points run simultaneously\n",
    "    by the model. Higher numbers may be faster but use more GPU memory.\n",
    "  pred_iou_thresh (float): A filtering threshold in [0,1], using the\n",
    "    model's predicted mask quality.\n",
    "  stability_score_thresh (float): A filtering threshold in [0,1], using\n",
    "    the stability of the mask under changes to the cutoff used to binarize\n",
    "    the model's mask predictions.\n",
    "  stability_score_offset (float): The amount to shift the cutoff when\n",
    "    calculated the stability score.\n",
    "  box_nms_thresh (float): The box IoU cutoff used by non-maximal\n",
    "    suppression to filter duplicate masks.\n",
    "  crop_n_layers (int): If >0, mask prediction will be run again on\n",
    "    crops of the image. Sets the number of layers to run, where each\n",
    "    layer has 2**i_layer number of image crops.\n",
    "  crop_nms_thresh (float): The box IoU cutoff used by non-maximal\n",
    "    suppression to filter duplicate masks between different crops.\n",
    "  crop_overlap_ratio (float): Sets the degree to which crops overlap.\n",
    "    In the first crop layer, crops will overlap by this fraction of\n",
    "    the image length. Later layers with more crops scale down this overlap.\n",
    "  crop_n_points_downscale_factor (int): The number of points-per-side\n",
    "    sampled in layer n is scaled down by crop_n_points_downscale_factor**n.\n",
    "  point_grids (list(np.ndarray) or None): A list over explicit grids\n",
    "    of points used for sampling, normalized to [0,1]. The nth grid in the\n",
    "    list is used in the nth crop layer. Exclusive with points_per_side.\n",
    "  min_mask_region_area (int): If >0, postprocessing will be applied\n",
    "    to remove disconnected regions and holes in masks with area smaller\n",
    "    than min_mask_region_area. Requires opencv.\n",
    "  output_mode (str): The form masks are returned in. Can be 'binary_mask',\n",
    "    'uncompressed_rle', or 'coco_rle'. 'coco_rle' requires pycocotools.\n",
    "    For large resolutions, 'binary_mask' may consume large amounts of\n",
    "    memory.\n",
    "    points_per_side: Optional[int] = 32,\n",
    "    points_per_batch: int = 64,\n",
    "    pred_iou_thresh: float = 0.88,\n",
    "    stability_score_thresh: float = 0.95,\n",
    "    stability_score_offset: float = 1.0,\n",
    "    box_nms_thresh: float = 0.7,\n",
    "    crop_n_layers: int = 0,\n",
    "    crop_nms_thresh: float = 0.7,\n",
    "    crop_overlap_ratio: float = 512 / 1500,\n",
    "    crop_n_points_downscale_factor: int = 1,\n",
    "    point_grids: Optional[List[np.ndarray]] = None,\n",
    "    min_mask_region_area: int = 0,\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    del sam\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "import torch\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "hd = True\n",
    "device = \"cpu\"\n",
    "\n",
    "if hd:\n",
    "    from segment_anything_hq import SamAutomaticMaskGenerator, sam_model_registry\n",
    "\n",
    "    sam = sam_model_registry[\"vit_h\"](\n",
    "        checkpoint=\"data/sam_weights/sam_hq_vit_h.pth\"\n",
    "    )\n",
    "    sam.to(device=device)\n",
    "else:\n",
    "    from segment_anything import SamAutomaticMaskGenerator, sam_model_registry\n",
    "\n",
    "    sam = sam_model_registry[\"vit_h\"](\n",
    "        checkpoint=\"data/sam_weights/sam_vit_h_4b8939.pth\"\n",
    "    )\n",
    "    sam.to(device=device)\n",
    "\n",
    "mask_generator = SamAutomaticMaskGenerator(\n",
    "    sam,\n",
    "    points_per_batch=32,  # nodig om geen OoM op de GPU te krijgen\n",
    ")\n",
    "\n",
    "plt.close(\"all\")\n",
    "for imgId in imgIds:\n",
    "    # COCO format img en annotation\n",
    "    img = coco.loadImgs(imgId)[0]\n",
    "\n",
    "    # Laad image in\n",
    "    imgPath = imgDir.joinpath(img[\"file_name\"])\n",
    "    imgRGB = skimage.io.imread(imgPath)\n",
    "    imgGray = skimage.io.imread(imgPath, as_gray=True)\n",
    "\n",
    "    # Laad annotation in\n",
    "    annIds = coco.getAnnIds(imgIds=img[\"id\"], catIds=catIds, iscrowd=None)\n",
    "    anns = coco.loadAnns(annIds)\n",
    "\n",
    "    # SAM mask\n",
    "    masks = mask_generator.generate(imgRGB)\n",
    "\n",
    "    # gesegmenteerd\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(imgGray, cmap=\"gray\")\n",
    "    coco.showAnns(anns, draw_bbox=True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # SAM\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(imgGray, cmap=\"gray\")\n",
    "    show_anns(masks)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8514998e-b4bf-4f58-96dd-9160602f7f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "voorbeeld_path = pathlib.Path(\n",
    "    \"276114_20230714 MUG Hoorn Enkhuizen orthomosaic deel 1/2023-12-11 10_00_58.048/images\"\n",
    ")\n",
    "\n",
    "df_files = dict(name=[], img_path=[])\n",
    "for p in voorbeeld_path.iterdir():\n",
    "    if p.suffix == \".json\" or p.suffix == \".jpeg\":\n",
    "        if p.stem not in df_files[\"name\"]:\n",
    "            df_files[\"name\"].append(p.stem)\n",
    "        #         if p.suffix == \".json\":\n",
    "        #             df_files[\"segment_path\"].append(str(p))\n",
    "        #         else:\n",
    "        df_files[\"img_path\"].append(str(p))\n",
    "    else:\n",
    "        print(f\"unknown filetype {p.suffix=}, {p}\")\n",
    "df_files = pd.DataFrame(df_files)\n",
    "display(df_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1115a0ac-2b8b-4937-920b-a1f13398153f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close(\"all\")\n",
    "\n",
    "for i, row in enumerate(df_files.itertuples()):\n",
    "    # Find tile bounds (X, Y) based on name\n",
    "    tile1a = row.name.split(\"_\")[0]\n",
    "    tile1b = int(row.name.split(\"_\")[-1])\n",
    "    cellfile = df_tilebounds[\n",
    "        (df_tilebounds.index == tile1b) & (df_tilebounds.name == tile1a)\n",
    "    ].copy()\n",
    "    assert len(cellfile) == 1\n",
    "    cellfile = cellfile.iloc[0, :].copy()\n",
    "    print(f\"  - {i+1:>02d}/{len(df_files):>02d} rgb tile: '{tile1a}' ('{tile1b}')\")\n",
    "\n",
    "    # Read image data\n",
    "    imgdata = matplotlib.image.imread(row.img_path)\n",
    "\n",
    "    # Read LIDAR data within the bounds of the image\n",
    "    matching_lasfiles = df_las[df_las.intersects(cellfile.geometry)].copy()\n",
    "    lidardata = []\n",
    "    for lasfile in matching_lasfiles.itertuples():\n",
    "        print(f\"    - las file: {lasfile.path}\")\n",
    "        array = get_lasdata(\n",
    "            lasfile.path, cellfile.xmin, cellfile.xmax, cellfile.ymin, cellfile.ymax\n",
    "        )\n",
    "        array[\"lasfile\"] = pathlib.Path(lasfile.path).stem\n",
    "        lidardata.append(array)\n",
    "    lidardata = pd.concat(lidardata, ignore_index=True)\n",
    "    xstep = (cellfile.xmax - cellfile.xmin) / imgdata.shape[1]\n",
    "    ystep = (cellfile.ymax - cellfile.ymin) / imgdata.shape[0]\n",
    "    lidardata[\"m\"] = ((cellfile.ymax - lidardata.Y) / ystep).astype(int)\n",
    "    lidardata[\"n\"] = ((lidardata.X - cellfile.xmin) / xstep).astype(int)\n",
    "\n",
    "    # Read segmentation data\n",
    "    lidardata_obj = []\n",
    "    with open(row.segment_path) as f:\n",
    "        # Read json data\n",
    "        jsondata = json.load(f)\n",
    "\n",
    "        # Read the bitmap masked data in the same shape as the imgdata\n",
    "        full_mask = {\n",
    "            \"opschot\": np.zeros((imgdata.shape[0], imgdata.shape[1]), dtype=bool),\n",
    "            \"gras steenbekleding\": np.zeros(\n",
    "                (imgdata.shape[0], imgdata.shape[1]), dtype=bool\n",
    "            ),\n",
    "            \"twijfel opschot\": np.zeros(\n",
    "                (imgdata.shape[0], imgdata.shape[1]), dtype=bool\n",
    "            ),\n",
    "        }\n",
    "        mask_bounds = []\n",
    "        for obj in jsondata[\"annotation\"][\"objects\"]:\n",
    "            cat_title = obj[\"classTitle\"]\n",
    "\n",
    "            # Update complete mask\n",
    "            bool_mask = base64_2_mask(obj[\"bitmap\"][\"data\"])\n",
    "            n1, m1 = obj[\"bitmap\"][\"origin\"]\n",
    "            m2 = m1 + bool_mask.shape[0]\n",
    "            n2 = n1 + bool_mask.shape[1]\n",
    "            full_mask[cat_title][m1:m2, n1:n2] = bool_mask\n",
    "\n",
    "            # mask bounds\n",
    "            bbox = shapely.box(n1, m1, n2, m2).boundary\n",
    "            mask_bounds.append((cat_title, bbox))\n",
    "\n",
    "            # relevant lidardata\n",
    "            sublidar = lidardata[\n",
    "                (lidardata.m >= m1)\n",
    "                & (lidardata.m < m2)\n",
    "                & (lidardata.n >= n1)\n",
    "                & (lidardata.n < n2)\n",
    "            ].copy()\n",
    "            lidardata_obj.append(sublidar)\n",
    "\n",
    "        mask_bounds = gpd.GeoDataFrame(\n",
    "            pd.DataFrame(mask_bounds, columns=[\"mask_type\", \"geometry\"]),\n",
    "            geometry=\"geometry\",\n",
    "        )\n",
    "\n",
    "    cat_int = {\n",
    "        \"opschot\": 1,\n",
    "        \"gras steenbekleding\": 2,\n",
    "        \"twijfel opschot\": 3,\n",
    "    }\n",
    "    fig, axs = plt.subplots(nrows=2, ncols=2, figsize=(12, 8), dpi=100)\n",
    "\n",
    "    # Show bounding boxes over image\n",
    "    axs[0, 0].pcolormesh(imgdata)\n",
    "    mask_bounds.plot(ax=axs[0, 0], column=\"mask_type\")\n",
    "    axs[0, 0].invert_yaxis()\n",
    "\n",
    "    # Show only the masked data with bounding boxes\n",
    "    mask_bounds.plot(\n",
    "        ax=axs[0, 1],\n",
    "        column=\"mask_type\",\n",
    "        legend=True,\n",
    "        legend_kwds={\"loc\": \"center left\"},\n",
    "    )\n",
    "    for obj_title, arrmask in full_mask.items():\n",
    "        if not arrmask.flatten().any():\n",
    "            continue\n",
    "        arrmask = np.tile(arrmask[:, :, np.newaxis], (1, 1, 3))\n",
    "        arrmask = np.ma.masked_array(imgdata, ~arrmask)\n",
    "        axs[0, 1].pcolormesh(arrmask)\n",
    "    axs[0, 1].invert_yaxis()\n",
    "    axs[0, 1].set_xlim(axs[0, 0].get_xlim())\n",
    "    axs[0, 1].set_ylim(axs[0, 0].get_ylim())\n",
    "    leg = axs[0, 1].get_legend()\n",
    "    leg.set_bbox_to_anchor((1, 0.5))\n",
    "\n",
    "    # Show lidar data with boxes\n",
    "    mask_bounds.plot(ax=axs[0, 1], column=\"mask_type\")\n",
    "    lidardata_plt = gpd.GeoDataFrame(\n",
    "        lidardata, geometry=gpd.GeoSeries.from_xy(lidardata.n, lidardata.m)\n",
    "    )\n",
    "    lidardata_plt.plot(ax=axs[1, 0], column=\"Z\")\n",
    "    axs[1, 0].invert_yaxis()\n",
    "    axs[1, 0].set_xlim(axs[0, 0].get_xlim())\n",
    "    axs[1, 0].set_ylim(axs[0, 0].get_ylim())\n",
    "\n",
    "    mask_bounds.plot(\n",
    "        ax=axs[1, 1],\n",
    "        column=\"mask_type\",\n",
    "        legend=True,\n",
    "        legend_kwds={\"loc\": \"center left\"},\n",
    "    )\n",
    "    for lidarsubset in lidardata_obj:\n",
    "        lidardata_plt = gpd.GeoDataFrame(\n",
    "            lidarsubset, geometry=gpd.GeoSeries.from_xy(lidarsubset.n, lidarsubset.m)\n",
    "        )\n",
    "        lidardata_plt.plot(ax=axs[1, 1], column=\"Z\")\n",
    "    axs[1, 1].invert_yaxis()\n",
    "    axs[1, 1].set_xlim(axs[0, 0].get_xlim())\n",
    "    axs[1, 1].set_ylim(axs[0, 0].get_ylim())\n",
    "    leg = axs[1, 1].get_legend()\n",
    "    leg.set_bbox_to_anchor((1, 0.5))\n",
    "\n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9207ab05-3207-4470-9ed7-cc5c88754ff4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce14b8e-22c4-4f18-9636-fecdcb5ff657",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:opschotdetectie2]",
   "language": "python",
   "name": "conda-env-opschotdetectie2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
